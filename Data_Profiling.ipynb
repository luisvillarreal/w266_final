{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luisarmandovillarreal/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, re, json, time\n",
    "import itertools, collections\n",
    "from importlib import reload\n",
    "from IPython.display import display\n",
    "import scipy.sparse\n",
    "import nltk\n",
    "from w266_common import utils, vocabulary, tf_embed_viz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting Tickers and Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two different data folders ('data' and 'data2'). This is because we first got all the tweets that mentioned name of stock as per the convention $ (ticker). \n",
    "\n",
    "Afterwards we got tweets that include names of companies along with their ticker symbols in the tweets. For example, we gathered any tweet that mentioned Amazon, and any tweet that mention $ (AMZN). This substantially increased our tweet count.\n",
    "\n",
    "Our tweets dataset consist of tweets pertaining to S&P500 Top 50 companies only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all the files in folder 'data'\n",
    "files = []\n",
    "for file in os.listdir('data'):\n",
    "    if file.endswith('.csv'):\n",
    "        files.append(os.path.join('data', file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe from files in 'data' folder\n",
    "\n",
    "data = []\n",
    "\n",
    "for filename in files:\n",
    "    with open(filename, 'r') as file:\n",
    "        ticker = filename.split('_')[-1][:-4]\n",
    "        line = file.readline()\n",
    "        line = file.readline()\n",
    "        while(line):\n",
    "            ts =line.split(';\"')[0][1:].split(';')[0]\n",
    "            tweet = line.split(';\"')[1].split('\";')[0]\n",
    "            tweet_id = line.split('/')[-1][:-1] \n",
    "            line=file.readline()\n",
    "            data.append([tweet_id,ticker,ts,tweet])\n",
    "        \n",
    "#df = pd.DataFrame(data, columns=['tweet_id','ticker','timestamp','tweet'])\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all the files in 'data2' folder\n",
    "files1 = []\n",
    "for file in os.listdir('data2'):\n",
    "    if file.endswith('.csv'):\n",
    "        files1.append(os.path.join('data2', file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe for files in 'data2' folder\n",
    "\n",
    "\n",
    "for filename in files1:\n",
    "    with open(filename, 'r') as file:\n",
    "        ticker = filename.split('_')[-1][:-4]\n",
    "        line = file.readline()\n",
    "        line = file.readline()\n",
    "        while(line):\n",
    "            ts =line.split(';\"')[0][1:].split(';')[0]\n",
    "            tweet = line.split(';\"')[1].split('\";')[0]\n",
    "            tweet_id = line.split('/')[-1][:-1] \n",
    "            line=file.readline()\n",
    "            data.append([tweet_id,ticker,ts,tweet])\n",
    "        \n",
    "df = pd.DataFrame(data, columns=['tweet_id','ticker','timestamp','tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from shapes of dataframes below, our first dataframe has considerably less tweets than the second one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155011, 4)\n",
      "(2989666, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1105569239845478401</td>\n",
       "      <td>DWDP</td>\n",
       "      <td>2019-03-12 20:40</td>\n",
       "      <td>4 nice trades today 3 swings ($csco $ dwdp $ m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1105566065369722885</td>\n",
       "      <td>DWDP</td>\n",
       "      <td>2019-03-12 20:27</td>\n",
       "      <td>$ AAPL - scaled out 2/3 into strength; 1/3 sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1105548846279450624</td>\n",
       "      <td>DWDP</td>\n",
       "      <td>2019-03-12 19:19</td>\n",
       "      <td>SLD 100 $ DWDP @55.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1105548512119283713</td>\n",
       "      <td>DWDP</td>\n",
       "      <td>2019-03-12 19:18</td>\n",
       "      <td>BOT $ DWDP Apr 55 call @2.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1105521484640980995</td>\n",
       "      <td>DWDP</td>\n",
       "      <td>2019-03-12 17:30</td>\n",
       "      <td># estate asset watch - stocks with momentum, 5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id ticker         timestamp  \\\n",
       "0  1105569239845478401   DWDP  2019-03-12 20:40   \n",
       "1  1105566065369722885   DWDP  2019-03-12 20:27   \n",
       "2  1105548846279450624   DWDP  2019-03-12 19:19   \n",
       "3  1105548512119283713   DWDP  2019-03-12 19:18   \n",
       "4  1105521484640980995   DWDP  2019-03-12 17:30   \n",
       "\n",
       "                                               tweet  \n",
       "0  4 nice trades today 3 swings ($csco $ dwdp $ m...  \n",
       "1  $ AAPL - scaled out 2/3 into strength; 1/3 sto...  \n",
       "2                              SLD 100 $ DWDP @55.69  \n",
       "3                       BOT $ DWDP Apr 55 call @2.34  \n",
       "4  # estate asset watch - stocks with momentum, 5...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_dict = {'Union':'UNP', 'Disney':'DIS', 'Nike':'NKE', 'Chevron':'CVX',\n",
    "                  'Intel':'INTC', 'Bank':'BAC', 'Pepsi':'PEP', 'Amgen':'AMGN',\n",
    "                  'AT&T':'T', 'Procter':'PG', 'Microsoft':'MSFT', 'Wells':'WFG',\n",
    "                  'Walmart':'WMT', 'Citigroup':'C', 'Verizon':'VZ', 'Exxon-Mobil':'XOM',\n",
    "                  'Apple':'AAPL', 'Mastercard':'MA', 'Merck':'MRK', 'Boeing':'BA', \n",
    "                  'Comcast':'CMCSA', 'Salesforce':'CRM', 'Home':'HD', 'Berkshire':'BRK',\n",
    "                  'Cisco':'CSCO', 'ATT':'T', 'Dow':'DWDP', 'Coca-Cola':'KO', 'Visa':'V',\n",
    "                  'Facebook':'FB', 'Johnson':'JNJ', 'Abbott':'ABBT', 'Broadcom':'AVGO',\n",
    "                  '3M':'MMM', 'Pfizer':'PFE', 'Amazon':'AMZN', 'Honeywell':'HON', 'Adobe':'ADBE',\n",
    "                  'Google':'GOOG', 'Netflix':'NFLX', 'Eli':'LLY', 'Phillips':'PM', 'United':'UNP',\n",
    "                  'AbbVie':'ABBV', 'McDonald':'MCD', 'JP':'JPM', 'Paypal':'PYPL', 'Oracle':'ORCL', \n",
    "                  'Medtronic':'MDT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medtronic          \r"
     ]
    }
   ],
   "source": [
    "# Associate tickers with company names\n",
    "\n",
    "for key, value in companies_dict.items():\n",
    "    \n",
    "    print(key,'       ', end='\\r')\n",
    "    df.loc[df['ticker'] == key, 'ticker'] = value\n",
    "    #combined_df.at[index, 'ticker'] = companies_dict[row['ticker']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Nasdaq Stock Symbols\n",
    "os.system(\"curl --ftp-ssl anonymous:jupi@jupi.com \"\n",
    "          \"ftp://ftp.nasdaqtrader.com/SymbolDirectory/nasdaqlisted.txt \"\n",
    "          \"> nasdaq.lst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html data-adblockkey=\"MFwwDQYJKoZIhvcNAQEBBQADSwAwSAJBANDrp2lz7AOmADaN8tA50LsWcjLFyQFcb/P2Txc58oYOeILb3vBw7J6f4pamkAQVSQuqYsKx3YzdUHCvbVZvFUsCAwEAAQ==_pxrolOu5yyzUS0zMNgm01mNbFq+3Njr33BJOzQ+JCg65FKwTyH/JswWy8wg/VocffrVzS1j7NXxyt+jJ2gFZsQ==\"><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"><title></title><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"><meta name=\"description\" content=\"See related links to what you are looking for.\"/></head><!--[if IE 6 ]><body class=\"ie6\"><![endif]--><!--[if IE 7 ]><body class=\"ie7\"><![endif]--><!--[if IE 8 ]><body class=\"ie8\"><![endif]--><!--[if IE 9 ]><body class=\"ie9\"><![endif]--><!--[if (gt IE 9)|!(IE)]> --><body><!--<![endif]--><script type=\"text/javascript\">g_pb=(function(){var\r\n",
      "DT=document,azy=location,DD=DT.createElement('script'),aAA=false,LU;DD.defer=true;DD.async=true;DD.src=\"//www.google.com/adsense/domains/caf.js\";DD.onerror=function(){if(azy.search!=='?z'){azy.href='/?z';}};DD.onload=DD.onreadystatechange=function(){if(!aAA&&LU){if(!window['googleNDT_']){}\r\n",
      "LU(google.ads.domains.Caf);}\r\n",
      "aAA=true;};DT.body.appendChild(DD);return{azl:function(n$){if(aAA)\r\n",
      "n$(google.ads.domains.Caf);else\r\n",
      "LU=n$;},bq:function(){if(!aAA){DT.body.removeChild(DD);}}};})();g_pd=(function(){var\r\n",
      "azy=window.location,nw={},bH,azw=azy.search.substring(1),aAs,aAu;if(!azw)\r\n",
      "return nw;aAs=azw.split(\"&\");for(bH=0;bH<aAs.length;bH++){aAu=aAs[bH].split('=');nw[aAu[0]]=aAu[1]?aAu[1]:\"\";}\r\n",
      "return nw;})();g_pc=(function(){var $is_ABP_whitelisted=null;var $Image1=new Image;var $Image2=new Image;var $error1=false;var $error2=false;var $remaining=2;var $random=Math.random()*11;function $imageLoaded(){$remaining--;if($remaining===0)\r\n",
      "$is_ABP_whitelisted=!$error1&&$error2;}\r\n",
      "$Image1.onload=$Image2.onload=$imageLoaded;$Image1.onerror=function(){$error1=true;$imageLoaded();};$Image2.onerror=function(){$error2=true;$imageLoaded();};$Image1.src='/px.gif?ch=1&rn='+$random;$Image2.src='/px.gif?ch=2&rn='+$random;return{azo:function(){return'&abp='+($is_ABP_whitelisted?'1':'0');},$isWhitelisted:function(){return $is_ABP_whitelisted;},$onReady:function($callback){function $poll(){if($is_ABP_whitelisted===null)\r\n",
      "setTimeout($poll,100);else $callback();}\r\n",
      "$poll();}}})();(function(){var aAm=screen,Rr=window,azy=Rr.location,aAz=top.location,DT=document,Sf=DT.body||DT.getElementsByTagName('body')[0],aAx=0,aAv=0,aAw=0,$IE=null;if(Sf.className==='ie6')\r\n",
      "$IE=6;else if(Sf.className==='ie7')\r\n",
      "$IE=7;else if(Sf.className==='ie8')\r\n",
      "$IE=8;else if(Sf.className==='ie9')\r\n",
      "$IE=9;function aAt($callback){aAw++;aAx=Rr.innerWidth||DT.documentElement.clientWidth||Sf.clientWidth;aAv=Rr.innerHeight||DT.documentElement.clientHeight||Sf.clientHeight;if(aAx>0||aAw>=5){$callback();}\r\n",
      "else{setTimeout(aAt,100);}}\r\n",
      "var $num_requirements=2;function $requirementMet(){$num_requirements--;if($num_requirements===0)\r\n",
      "aAy();}\r\n",
      "aAt($requirementMet);g_pc.$onReady($requirementMet);function aAy(){var ef=undefined,IQ=encodeURIComponent,aAr;if(aAz!=azy&&g_pd.r_s===ef)\r\n",
      "aAz.href=azy.href;aAr=DT.createElement('script');aAr.type='text/javascript';aAr.src='/glp'+'?r='+(g_pd.r!==ef?g_pd.r:(DT.referrer?IQ(DT.referrer.substr(0,255)):''))+\r\n",
      "(g_pd.r_u?'&u='+g_pd.r_u:'&u='+IQ(azy.href.split('?')[0]))+\r\n",
      "(g_pd.gc?'&gc='+g_pd.gc:'')+\r\n",
      "(g_pd.cid?'&cid='+g_pd.cid:'')+\r\n",
      "(g_pd.query?'&sq='+g_pd.query:'')+\r\n",
      "(g_pd.search?'&ss=1':'')+\r\n",
      "(g_pd.a!==ef?'&a':'')+\r\n",
      "(g_pd.z!==ef?'&z':'')+\r\n",
      "(g_pd.z_ds!==ef?'&z_ds':'')+\r\n",
      "(g_pd.r_s!==ef?'&r_s='+g_pd.r_s:'')+\r\n",
      "(g_pd.r_d!==ef?'&r_d='+g_pd.r_d:'')+'&rw='+aAm.width+'&rh='+aAm.height+\r\n",
      "(g_pd.r_ww!==ef?'&ww='+g_pd.r_ww:'&ww='+aAx)+\r\n",
      "(g_pd.r_wh!==ef?'&wh='+g_pd.r_wh:'&wh='+aAv)+\r\n",
      "(g_pc.$isWhitelisted()?'&abp=1':'')+\r\n",
      "($IE!==null?'&ie='+$IE:'')+\r\n",
      "(g_pd.partner!==ef?'&partner='+g_pd.partner:'')+\r\n",
      "(g_pd.subid1!==ef?'&subid1='+g_pd.subid1:'')+\r\n",
      "(g_pd.subid2!==ef?'&subid2='+g_pd.subid2:'')+\r\n",
      "(g_pd.subid3!==ef?'&subid3='+g_pd.subid3:'')+\r\n",
      "(g_pd.subid4!==ef?'&subid4='+g_pd.subid4:'')+\r\n",
      "(g_pd.subid5!==ef?'&subid5='+g_pd.subid5:'');Sf.appendChild(aAr);}})();</script></body></html>Symbol|Security Name|Market Category|Test Issue|Financial Status|Round Lot Size|ETF|NextShares\r",
      "\r\n",
      "AABA|Altaba Inc. - Common Stock|Q|N|N|100|N|N\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head -43 nasdaq.lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZSAN|Zosano Pharma Corporation - Common Stock|S|N|N|100|N|N\r",
      "\r\n",
      "ZUMZ|Zumiez Inc. - Common Stock|Q|N|N|100|N|N\r",
      "\r\n",
      "ZVZZC|NASDAQ TEST STOCK Nextshares Test Security|G|Y|N|100||Y\r",
      "\r\n",
      "ZVZZT|NASDAQ TEST STOCK|G|Y|N|100||N\r",
      "\r\n",
      "ZWZZT|NASDAQ TEST STOCK|S|Y|N|100||N\r",
      "\r\n",
      "ZXYZ.A|Nasdaq Symbology Test Common Stock|Q|Y|N|100||N\r",
      "\r\n",
      "ZXZZT|NASDAQ TEST STOCK|G|Y|N|100||N\r",
      "\r\n",
      "ZYNE|Zynerba Pharmaceuticals, Inc. - Common Stock|G|N|N|100|N|N\r",
      "\r\n",
      "ZYXI|Zynex, Inc. - Common Stock|S|N|N|100|N|N\r",
      "\r\n",
      "File Creation Time: 0405201921:31|||||||\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!tail -10 nasdaq.lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -n +43 nasdaq.lst | cat | sed '$d' | sed 's/|/ /g' > nasdaq.lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "AABA Altaba Inc. - Common Stock Q N N 100 N N\r",
      "\r\n",
      "AAL American Airlines Group, Inc. - Common Stock Q N N 100 N N\r",
      "\r\n",
      "AAME Atlantic American Corporation - Common Stock G N N 100 N N\r",
      "\r\n",
      "AAOI Applied Optoelectronics, Inc. - Common Stock G N N 100 N N\r",
      "\r\n",
      "AAON AAON, Inc. - Common Stock Q N N 100 N N\r",
      "\r\n",
      "AAPL Apple Inc. - Common Stock Q N N 100 N N\r",
      "\r\n",
      "AAWW Atlas Air Worldwide Holdings - Common Stock Q N N 100 N N\r",
      "\r\n",
      "AAXJ iShares MSCI All Country Asia ex Japan Index Fund G N N 100 Y N\r",
      "\r\n",
      "AAXN Axon Enterprise, Inc. - Common Stock Q N N 100 N N\r",
      "\r\n",
      "ABCB Ameris Bancorp - Common Stock Q N N 100 N N\r",
      "\r\n",
      "...\r\n",
      "ZS Zscaler, Inc. - Common Stock Q N N 100 N N\r",
      "\r\n",
      "ZSAN Zosano Pharma Corporation - Common Stock S N N 100 N N\r",
      "\r\n",
      "ZUMZ Zumiez Inc. - Common Stock Q N N 100 N N\r",
      "\r\n",
      "ZVZZC NASDAQ TEST STOCK Nextshares Test Security G Y N 100  Y\r",
      "\r\n",
      "ZVZZT NASDAQ TEST STOCK G Y N 100  N\r",
      "\r\n",
      "ZWZZT NASDAQ TEST STOCK S Y N 100  N\r",
      "\r\n",
      "ZXYZ.A Nasdaq Symbology Test Common Stock Q Y N 100  N\r",
      "\r\n",
      "ZXZZT NASDAQ TEST STOCK G Y N 100  N\r",
      "\r\n",
      "ZYNE Zynerba Pharmaceuticals, Inc. - Common Stock G N N 100 N N\r",
      "\r\n",
      "ZYXI Zynex, Inc. - Common Stock S N N 100 N N\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!echo; head nasdaq.lst2; echo \"...\"; tail nasdaq.lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!awk '{print $1}' nasdaq.lst2 > nasdaq.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = pd.read_csv('nasdaq.csv', index_col=None, header=None)\n",
    "tickers.columns = ['ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get NYSE Symbols\n",
    "nyse = pd.read_csv('companylist.csv')\n",
    "cols = [1,2,3,4,5,6,7,8,9]\n",
    "nyse.drop(nyse.columns[cols],axis=1,inplace=True)\n",
    "nyse.columns = ['ticker']\n",
    "tickers = tickers.append(nyse)\n",
    "tickers = list(tickers['ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets associated with more than one stock: 542,968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2601709, 4)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Tweets associated with more than one stock...\n",
    "\n",
    "# First, using the tweet id...\n",
    "g = df.groupby('tweet_id').size().reset_index(name='count')\n",
    "print('Tweets associated with more than one stock:',\"{:,}\".format(sum(g[g['count']>1]['count'])))\n",
    "\n",
    "# Delete those tweet ids\n",
    "tweets_ids_to_drop = list(g[g['count']>1]['tweet_id'])\n",
    "df = df[~df.tweet_id.isin(tweets_ids_to_drop)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors from data/glove/glove.6B.zip\n",
      "Parsing file: data/glove/glove.6B.zip:glove.6B.100d.txt\n",
      "Found 400,000 words.\n",
      "Parsing vectors... Done! (W.shape = (400003, 100))\n"
     ]
    }
   ],
   "source": [
    "# This one takes a while when run for the first time\n",
    "\n",
    "import glove_helper; reload(glove_helper)\n",
    "\n",
    "hands = glove_helper.Hands(ndim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3144676\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>110526365952428032</td>\n",
       "      <td>DWDP</td>\n",
       "      <td>2019-03-12 00:26</td>\n",
       "      <td>&lt;s&gt; traders sell shares of $ on strength $ &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1103805919568293888</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-07 23:53</td>\n",
       "      <td>&lt;s&gt; @ ich $ @ ich @ &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1103801007375552514</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-07 23:34</td>\n",
       "      <td>&lt;s&gt; $ house democrats seek details of trump ef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1103735736153432064</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-07 19:14</td>\n",
       "      <td>&lt;s&gt; $ t - two new revenue streams … … @ att @ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1103724496027115520</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-07 18:30</td>\n",
       "      <td>&lt;s&gt; telus co. declares quarterly dividend of $...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1103672373990080517</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-07 15:02</td>\n",
       "      <td>&lt;s&gt; a t &amp; t $ t shareholder douglass winthrop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1103671152411635712</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-07 14:58</td>\n",
       "      <td>&lt;s&gt; not an exciting stock but $ t is green - l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1103556398334521344</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-07 07:22</td>\n",
       "      <td>&lt;s&gt; $ content chief says competitors eating ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1103547615923392512</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-07 06:47</td>\n",
       "      <td>&lt;s&gt; $ $ $ newmont rejects barrick takeover … &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1103547608113602560</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-07 06:47</td>\n",
       "      <td>&lt;s&gt; $ $ high-speed rail in the u.s. remains il...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1103547357218725888</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-07 06:46</td>\n",
       "      <td>&lt;s&gt; $ $ biggest shareholder opposes acquisitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1103547118587908096</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-07 06:45</td>\n",
       "      <td>&lt;s&gt; $ confidant of embattled trudeau says gove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>110344518985786982</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-07 00:00</td>\n",
       "      <td>&lt;s&gt; wed mar 06 art 2019 $ t has weekly in phas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1109027037099053056</td>\n",
       "      <td>CRM</td>\n",
       "      <td>2019-03-22 09:40</td>\n",
       "      <td>&lt;s&gt; , inc. $ crm ceo keith block sells 5,000 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1109019472461991936</td>\n",
       "      <td>CRM</td>\n",
       "      <td>2019-03-22 09:10</td>\n",
       "      <td>&lt;s&gt; insider , inc. $ crm chairman sells 10,000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>1108932425868931072</td>\n",
       "      <td>CRM</td>\n",
       "      <td>2019-03-22 03:24</td>\n",
       "      <td>&lt;s&gt; , inc. $ crm director john victor roos sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1108931301782908928</td>\n",
       "      <td>CRM</td>\n",
       "      <td>2019-03-22 03:19</td>\n",
       "      <td>&lt;s&gt; , inc. $ crm general counsel sells in stoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>1108887096197038088</td>\n",
       "      <td>CRM</td>\n",
       "      <td>2019-03-22 00:24</td>\n",
       "      <td>&lt;s&gt; inc director just disposed of 113 shares …...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1108885579876519936</td>\n",
       "      <td>CRM</td>\n",
       "      <td>2019-03-22 00:18</td>\n",
       "      <td>&lt;s&gt; chairman of the board co-ceo just disposed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1108883802221367296</td>\n",
       "      <td>CRM</td>\n",
       "      <td>2019-03-22 00:11</td>\n",
       "      <td>&lt;s&gt; pres. and chief people officer just dispos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>110888373126639206</td>\n",
       "      <td>CRM</td>\n",
       "      <td>2019-03-22 00:10</td>\n",
       "      <td>&lt;s&gt; $ spy $ robbins cynthia g. disposed stocks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>110852774883696640</td>\n",
       "      <td>PYPL</td>\n",
       "      <td>2019-03-21 00:36</td>\n",
       "      <td>&lt;s&gt; $ spx $ spy $ spx $ aapl $ fb $ $ c $ $ $ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>1104163399359819776</td>\n",
       "      <td>PM</td>\n",
       "      <td>2019-03-08 23:34</td>\n",
       "      <td>&lt;s&gt; philip morris international upgraded by ub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>1104137499146964993</td>\n",
       "      <td>PM</td>\n",
       "      <td>2019-03-08 21:51</td>\n",
       "      <td>&lt;s&gt; philip morris international inc. $ pm rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>1104137180883111937</td>\n",
       "      <td>PM</td>\n",
       "      <td>2019-03-08 21:49</td>\n",
       "      <td>&lt;s&gt; philip morris international inc. $ pm give...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>1104092604990398464</td>\n",
       "      <td>PM</td>\n",
       "      <td>2019-03-08 18:52</td>\n",
       "      <td>&lt;s&gt; $ pm - philip morris faces probe in india ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>1104025509237833729</td>\n",
       "      <td>PM</td>\n",
       "      <td>2019-03-08 14:26</td>\n",
       "      <td>&lt;s&gt; philip morris international inc. $ pm decl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>1104025506557644807</td>\n",
       "      <td>PM</td>\n",
       "      <td>2019-03-08 14:26</td>\n",
       "      <td>&lt;s&gt; philip morris international inc. $ pm decl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>1104024626110365696</td>\n",
       "      <td>PM</td>\n",
       "      <td>2019-03-08 14:22</td>\n",
       "      <td>&lt;s&gt; philip morris international inc. announces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>1104022368819863552</td>\n",
       "      <td>PM</td>\n",
       "      <td>2019-03-08 14:13</td>\n",
       "      <td>&lt;s&gt; $ pm … &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112198</th>\n",
       "      <td>1110693096549957632</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-27 00:00</td>\n",
       "      <td>&lt;s&gt; du på att sour cola eller för din vår rece...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112199</th>\n",
       "      <td>1110693091206463489</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-27 00:00</td>\n",
       "      <td>&lt;s&gt; gör ju inte du det som min som jag genom a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112200</th>\n",
       "      <td>1110693043731132416</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-27 00:00</td>\n",
       "      <td>&lt;s&gt; a cable been stretched across my lawn for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112201</th>\n",
       "      <td>1110693028900028421</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-27 00:00</td>\n",
       "      <td>&lt;s&gt; pelo amor de deus traz só mais uma att … &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112202</th>\n",
       "      <td>1110692982271799296</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-27 00:00</td>\n",
       "      <td>&lt;s&gt; de är de vi haft som inte och för att ska ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112203</th>\n",
       "      <td>1110692968925671424</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-27 00:00</td>\n",
       "      <td>&lt;s&gt; ah partir de mtn je donc wsh att en gros à...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112204</th>\n",
       "      <td>1110692957374558208</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-27 00:00</td>\n",
       "      <td>&lt;s&gt; det i är att de som har goda och att sitte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112205</th>\n",
       "      <td>1110692946880446464</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-27 00:00</td>\n",
       "      <td>&lt;s&gt; den har har du fler alias så kan du dom ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112206</th>\n",
       "      <td>1110692926160601097</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-27 00:00</td>\n",
       "      <td>&lt;s&gt; att jag bodde i usa med på min att de vill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112207</th>\n",
       "      <td>1110692912021409792</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-27 00:00</td>\n",
       "      <td>&lt;s&gt; win your @ studio session april 9th in our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3115356</th>\n",
       "      <td>1110659456206061570</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 21:47</td>\n",
       "      <td>&lt;s&gt; dum men lita på att d e en &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118175</th>\n",
       "      <td>1110645351499907072</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 20:51</td>\n",
       "      <td>&lt;s&gt; man som pappa utan att heta peter haber så...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118610</th>\n",
       "      <td>1110643511160946688</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 20:43</td>\n",
       "      <td>&lt;s&gt; alltid att se fram &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3119492</th>\n",
       "      <td>1110639674782044160</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 20:28</td>\n",
       "      <td>&lt;s&gt; att veronica maggio nytt i med att ut är e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120010</th>\n",
       "      <td>1110636942218199045</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 20:17</td>\n",
       "      <td>&lt;s&gt; så det var som som lagen om mot var att # ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3121655</th>\n",
       "      <td>1110627262800584709</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 19:39</td>\n",
       "      <td>&lt;s&gt; det finns saker att under en ..... och vi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123845</th>\n",
       "      <td>1110613312570605569</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 18:43</td>\n",
       "      <td>&lt;s&gt; moi quand les gens sont mais att c ton vra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125101</th>\n",
       "      <td>1110605190389006336</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 18:11</td>\n",
       "      <td>&lt;s&gt; ? att mr trump får till &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125940</th>\n",
       "      <td>1110599562614505472</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 17:49</td>\n",
       "      <td>&lt;s&gt; 30 días después comisión que # del preside...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128620</th>\n",
       "      <td>1110581369820901382</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 16:36</td>\n",
       "      <td>&lt;s&gt; in på badoo för att med fredric och folk i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3129254</th>\n",
       "      <td>1110576942686892032</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 16:19</td>\n",
       "      <td>&lt;s&gt; i do look att both all facts mj fans throw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131764</th>\n",
       "      <td>1110558366491992066</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 15:05</td>\n",
       "      <td>&lt;s&gt; de för att är &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132982</th>\n",
       "      <td>1110549064255528960</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 14:28</td>\n",
       "      <td>&lt;s&gt; som att det kommer ta 2 år att lagen så ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134478</th>\n",
       "      <td>1110537607765770240</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 13:42</td>\n",
       "      <td>&lt;s&gt; krm va att jag saker som i &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137400</th>\n",
       "      <td>1110514011429310464</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 12:09</td>\n",
       "      <td>&lt;s&gt; så har du att ta ner henne till gotland el...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137912</th>\n",
       "      <td>1110510124274253824</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 11:53</td>\n",
       "      <td>&lt;s&gt; jag har absolut inga på att klara men nu ä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142806</th>\n",
       "      <td>1110468302088953857</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 09:07</td>\n",
       "      <td>&lt;s&gt; sedan att isas val i usa igen o fr pk medi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3142942</th>\n",
       "      <td>1110467298094125057</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 09:03</td>\n",
       "      <td>&lt;s&gt; just för hillary var alla på och till om a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3143181</th>\n",
       "      <td>1110465415455612928</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 08:56</td>\n",
       "      <td>&lt;s&gt; pk media kommer aldrig att trump president...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3144676</th>\n",
       "      <td>111045283565579468</td>\n",
       "      <td>T</td>\n",
       "      <td>2019-03-26 08:06</td>\n",
       "      <td>&lt;s&gt; att fo que je zoom &lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2576244 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet_id ticker         timestamp  \\\n",
       "24        110526365952428032   DWDP  2019-03-12 00:26   \n",
       "25       1103805919568293888      T  2019-03-07 23:53   \n",
       "26       1103801007375552514      T  2019-03-07 23:34   \n",
       "56       1103735736153432064      T  2019-03-07 19:14   \n",
       "63       1103724496027115520      T  2019-03-07 18:30   \n",
       "103      1103672373990080517      T  2019-03-07 15:02   \n",
       "104      1103671152411635712      T  2019-03-07 14:58   \n",
       "178      1103556398334521344      T  2019-03-07 07:22   \n",
       "179      1103547615923392512      T  2019-03-07 06:47   \n",
       "180      1103547608113602560      T  2019-03-07 06:47   \n",
       "183      1103547357218725888      T  2019-03-07 06:46   \n",
       "188      1103547118587908096      T  2019-03-07 06:45   \n",
       "207       110344518985786982      T  2019-03-07 00:00   \n",
       "289      1109027037099053056    CRM  2019-03-22 09:40   \n",
       "290      1109019472461991936    CRM  2019-03-22 09:10   \n",
       "301      1108932425868931072    CRM  2019-03-22 03:24   \n",
       "304      1108931301782908928    CRM  2019-03-22 03:19   \n",
       "326      1108887096197038088    CRM  2019-03-22 00:24   \n",
       "329      1108885579876519936    CRM  2019-03-22 00:18   \n",
       "331      1108883802221367296    CRM  2019-03-22 00:11   \n",
       "333       110888373126639206    CRM  2019-03-22 00:10   \n",
       "422       110852774883696640   PYPL  2019-03-21 00:36   \n",
       "423      1104163399359819776     PM  2019-03-08 23:34   \n",
       "425      1104137499146964993     PM  2019-03-08 21:51   \n",
       "426      1104137180883111937     PM  2019-03-08 21:49   \n",
       "440      1104092604990398464     PM  2019-03-08 18:52   \n",
       "452      1104025509237833729     PM  2019-03-08 14:26   \n",
       "453      1104025506557644807     PM  2019-03-08 14:26   \n",
       "454      1104024626110365696     PM  2019-03-08 14:22   \n",
       "455      1104022368819863552     PM  2019-03-08 14:13   \n",
       "...                      ...    ...               ...   \n",
       "3112198  1110693096549957632      T  2019-03-27 00:00   \n",
       "3112199  1110693091206463489      T  2019-03-27 00:00   \n",
       "3112200  1110693043731132416      T  2019-03-27 00:00   \n",
       "3112201  1110693028900028421      T  2019-03-27 00:00   \n",
       "3112202  1110692982271799296      T  2019-03-27 00:00   \n",
       "3112203  1110692968925671424      T  2019-03-27 00:00   \n",
       "3112204  1110692957374558208      T  2019-03-27 00:00   \n",
       "3112205  1110692946880446464      T  2019-03-27 00:00   \n",
       "3112206  1110692926160601097      T  2019-03-27 00:00   \n",
       "3112207  1110692912021409792      T  2019-03-27 00:00   \n",
       "3115356  1110659456206061570      T  2019-03-26 21:47   \n",
       "3118175  1110645351499907072      T  2019-03-26 20:51   \n",
       "3118610  1110643511160946688      T  2019-03-26 20:43   \n",
       "3119492  1110639674782044160      T  2019-03-26 20:28   \n",
       "3120010  1110636942218199045      T  2019-03-26 20:17   \n",
       "3121655  1110627262800584709      T  2019-03-26 19:39   \n",
       "3123845  1110613312570605569      T  2019-03-26 18:43   \n",
       "3125101  1110605190389006336      T  2019-03-26 18:11   \n",
       "3125940  1110599562614505472      T  2019-03-26 17:49   \n",
       "3128620  1110581369820901382      T  2019-03-26 16:36   \n",
       "3129254  1110576942686892032      T  2019-03-26 16:19   \n",
       "3131764  1110558366491992066      T  2019-03-26 15:05   \n",
       "3132982  1110549064255528960      T  2019-03-26 14:28   \n",
       "3134478  1110537607765770240      T  2019-03-26 13:42   \n",
       "3137400  1110514011429310464      T  2019-03-26 12:09   \n",
       "3137912  1110510124274253824      T  2019-03-26 11:53   \n",
       "3142806  1110468302088953857      T  2019-03-26 09:07   \n",
       "3142942  1110467298094125057      T  2019-03-26 09:03   \n",
       "3143181  1110465415455612928      T  2019-03-26 08:56   \n",
       "3144676   111045283565579468      T  2019-03-26 08:06   \n",
       "\n",
       "                                                     tweet  \n",
       "24         <s> traders sell shares of $ on strength $ </s>  \n",
       "25                                <s> @ ich $ @ ich @ </s>  \n",
       "26       <s> $ house democrats seek details of trump ef...  \n",
       "56       <s> $ t - two new revenue streams … … @ att @ ...  \n",
       "63       <s> telus co. declares quarterly dividend of $...  \n",
       "103      <s> a t & t $ t shareholder douglass winthrop ...  \n",
       "104      <s> not an exciting stock but $ t is green - l...  \n",
       "178      <s> $ content chief says competitors eating ou...  \n",
       "179      <s> $ $ $ newmont rejects barrick takeover … </s>  \n",
       "180      <s> $ $ high-speed rail in the u.s. remains il...  \n",
       "183      <s> $ $ biggest shareholder opposes acquisitio...  \n",
       "188      <s> $ confidant of embattled trudeau says gove...  \n",
       "207      <s> wed mar 06 art 2019 $ t has weekly in phas...  \n",
       "289      <s> , inc. $ crm ceo keith block sells 5,000 s...  \n",
       "290      <s> insider , inc. $ crm chairman sells 10,000...  \n",
       "301      <s> , inc. $ crm director john victor roos sel...  \n",
       "304      <s> , inc. $ crm general counsel sells in stoc...  \n",
       "326      <s> inc director just disposed of 113 shares …...  \n",
       "329      <s> chairman of the board co-ceo just disposed...  \n",
       "331      <s> pres. and chief people officer just dispos...  \n",
       "333      <s> $ spy $ robbins cynthia g. disposed stocks...  \n",
       "422      <s> $ spx $ spy $ spx $ aapl $ fb $ $ c $ $ $ ...  \n",
       "423      <s> philip morris international upgraded by ub...  \n",
       "425      <s> philip morris international inc. $ pm rece...  \n",
       "426      <s> philip morris international inc. $ pm give...  \n",
       "440      <s> $ pm - philip morris faces probe in india ...  \n",
       "452      <s> philip morris international inc. $ pm decl...  \n",
       "453      <s> philip morris international inc. $ pm decl...  \n",
       "454      <s> philip morris international inc. announces...  \n",
       "455                                        <s> $ pm … </s>  \n",
       "...                                                    ...  \n",
       "3112198  <s> du på att sour cola eller för din vår rece...  \n",
       "3112199  <s> gör ju inte du det som min som jag genom a...  \n",
       "3112200  <s> a cable been stretched across my lawn for ...  \n",
       "3112201  <s> pelo amor de deus traz só mais uma att … </s>  \n",
       "3112202  <s> de är de vi haft som inte och för att ska ...  \n",
       "3112203  <s> ah partir de mtn je donc wsh att en gros à...  \n",
       "3112204  <s> det i är att de som har goda och att sitte...  \n",
       "3112205  <s> den har har du fler alias så kan du dom ti...  \n",
       "3112206  <s> att jag bodde i usa med på min att de vill...  \n",
       "3112207  <s> win your @ studio session april 9th in our...  \n",
       "3115356                <s> dum men lita på att d e en </s>  \n",
       "3118175  <s> man som pappa utan att heta peter haber så...  \n",
       "3118610                        <s> alltid att se fram </s>  \n",
       "3119492  <s> att veronica maggio nytt i med att ut är e...  \n",
       "3120010  <s> så det var som som lagen om mot var att # ...  \n",
       "3121655  <s> det finns saker att under en ..... och vi ...  \n",
       "3123845  <s> moi quand les gens sont mais att c ton vra...  \n",
       "3125101                   <s> ? att mr trump får till </s>  \n",
       "3125940  <s> 30 días después comisión que # del preside...  \n",
       "3128620  <s> in på badoo för att med fredric och folk i...  \n",
       "3129254  <s> i do look att both all facts mj fans throw...  \n",
       "3131764                             <s> de för att är </s>  \n",
       "3132982  <s> som att det kommer ta 2 år att lagen så ja...  \n",
       "3134478                <s> krm va att jag saker som i </s>  \n",
       "3137400  <s> så har du att ta ner henne till gotland el...  \n",
       "3137912  <s> jag har absolut inga på att klara men nu ä...  \n",
       "3142806  <s> sedan att isas val i usa igen o fr pk medi...  \n",
       "3142942  <s> just för hillary var alla på och till om a...  \n",
       "3143181  <s> pk media kommer aldrig att trump president...  \n",
       "3144676                        <s> att fo que je zoom </s>  \n",
       "\n",
       "[2576244 rows x 4 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Second, discard tweets that mention multiple stocks\n",
    "# This one takes a while, hang in there\n",
    "# Take advantage of the whole iteration and transform tweet for classifier\n",
    "df_duplicate = df.copy()\n",
    "\n",
    "TOKEN_RE = re.compile(r\"\\w.*?\\b\")\n",
    "indices_to_drop = []\n",
    "\n",
    "for index, row in df_duplicate.iterrows():\n",
    "    \n",
    "    print(index,end='\\r')\n",
    "\n",
    "    tweet_no_url = re.sub(r'http\\S+', '', row['tweet'])\n",
    "    tokens = tweet_no_url.split(' ')\n",
    "    sentence = '<s> '\n",
    "    flag = True\n",
    "    prev_token = ''\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            a = hands.vocab.word_to_id[token.lower()]\n",
    "            sentence = sentence + token.lower() + ' '\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if token in tickers and prev_token == '$':\n",
    "\n",
    "            if token != row['ticker']:\n",
    "                indices_to_drop.append(index)\n",
    "                flag=False\n",
    "                break\n",
    "        \n",
    "        prev_token = token\n",
    "    \n",
    "    sentence += '</s>'\n",
    "    \n",
    "    if flag:\n",
    "        \n",
    "        df_duplicate.at[index,'tweet'] = re.sub('[^A-Za-z0-9]+', '', sentence)\n",
    "\n",
    "df_duplicate.drop(indices_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicate.to_csv('data/clean_tweets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
